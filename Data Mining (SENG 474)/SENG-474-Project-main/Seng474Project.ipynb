{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jams in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.3.4)\n",
      "Requirement already satisfied: jsonschema>=3.0.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jams) (4.4.0)\n",
      "Requirement already satisfied: six in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jams) (1.15.0)\n",
      "Requirement already satisfied: mir-eval>=0.5 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jams) (0.7)\n",
      "Requirement already satisfied: pandas in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jams) (1.4.1)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jams) (2.4.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jams) (5.1.1)\n",
      "Requirement already satisfied: numpy>=1.8.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jams) (1.19.5)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jsonschema>=3.0.0->jams) (0.18.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jsonschema>=3.0.0->jams) (21.4.0)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mir-eval>=0.5->jams) (1.8.0)\n",
      "Requirement already satisfied: future in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mir-eval>=0.5->jams) (0.18.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->jams) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->jams) (2.8.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (4.29.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (9.0.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (1.19.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (3.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
      "Collecting audiolazy\n",
      "  Using cached audiolazy-0.6-py2.py3-none-any.whl (121 kB)\n",
      "Installing collected packages: audiolazy\n",
      "Successfully installed audiolazy-0.6\n",
      "Requirement already satisfied: librosa in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.8.0)\n",
      "Requirement already satisfied: audioread>=2.0.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from librosa) (2.1.9)\n",
      "Requirement already satisfied: pooch>=1.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from librosa) (1.6.0)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from librosa) (1.8.0)\n",
      "Requirement already satisfied: soundfile>=0.9.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from librosa) (0.10.3.post1)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from librosa) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from librosa) (1.19.5)\n",
      "Requirement already satisfied: resampy>=0.2.2 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from librosa) (0.2.2)\n",
      "Requirement already satisfied: decorator>=3.0.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.43.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from librosa) (0.53.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from numba>=0.43.0->librosa) (49.2.1)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from numba>=0.43.0->librosa) (0.36.0)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pooch>=1.0->librosa) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pooch>=1.0->librosa) (21.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pooch>=1.0->librosa) (2.27.1)\n",
      "Requirement already satisfied: six>=1.3 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from soundfile>=0.9.0->librosa) (1.15.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from cffi>=1.0->soundfile>=0.9.0->librosa) (2.21)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from packaging>=20.0->pooch>=1.0->librosa) (3.0.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3)\n",
      "Requirement already satisfied: music21 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (7.1.0)\n",
      "Requirement already satisfied: chardet in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from music21) (4.0.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from music21) (1.1.0)\n",
      "Requirement already satisfied: webcolors>=1.5 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from music21) (1.11.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from music21) (3.5.1)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from music21) (8.12.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from music21) (1.19.5)\n",
      "Requirement already satisfied: jsonpickle in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from music21) (2.1.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->music21) (9.0.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->music21) (4.29.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->music21) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->music21) (3.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->music21) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->music21) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->music21) (1.3.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->music21) (1.15.0)\n",
      "Requirement already satisfied: MIDIUtil in c:\\users\\drpag\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install jams\n",
    "!pip install matplotlib\n",
    "!pip install audiolazy\n",
    "!pip install librosa\n",
    "!pip3 install music21\n",
    "!pip3 install MIDIUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import scipy.io.wavfile as wav\n",
    "import jams\n",
    "\n",
    "import librosa\n",
    "import audiolazy as al\n",
    "\n",
    "import music21\n",
    "from midiutil import MIDIFile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Data Input (Guitar Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract note/time information from JAM file\n",
    "def loadNoteData(f):\n",
    "    data = jams.load(f)\n",
    "    notes = []\n",
    "\n",
    "    for i in range (0, 6):\n",
    "        for j in data.annotations[\"note_midi\"][i][\"data\"]:\n",
    "            notes.append([j[0],j[1],j[2]])\n",
    "            \n",
    "    notes.sort(key=timeKey)\n",
    "\n",
    "    return notes\n",
    "\n",
    "# Helper function for JAM file processing\n",
    "def timeKey(t):\n",
    "    return t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to handle loading audio files\n",
    "def load_audio_file(song_path, scale = False):\n",
    "    srate, source_audio = wav.read(song_path)\n",
    "    if scale:\n",
    "        source_audio = source_audio.astype(np.float32) / max(max(source_audio),abs(min(source_audio)))\n",
    "\n",
    "    return source_audio, srate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process the raw audio data (x data)\n",
    "# local - uses sklearn MinMaxScaler. each \"frame\" has local -1,1 scaling\n",
    "# global - entire x dataset scaled by largest absolute value to -1,1\n",
    "def x_data_process(raw_data, scale = 'local'):\n",
    "    if scale == 'local':\n",
    "        scaler = preprocessing.MinMaxScaler((-1,1))\n",
    "        scaled = scaler.fit_transform(raw_data)\n",
    "    elif scale == 'global':\n",
    "        scaled = raw_data.copy() / max(np.absolute(np.array(raw_data).flatten()))\n",
    "    else:\n",
    "        scaled = raw_data\n",
    "    return scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to pad x data so all frames are same length\n",
    "def pad(proper_size, frame):\n",
    "    padsize = winSize-len(frame)\n",
    "    temp = None\n",
    "    if len(frame.shape) > 1:\n",
    "        temp = np.zeros((frame.shape[0],padsize))\n",
    "    else:\n",
    "        temp = np.zeros(padsize)\n",
    "\n",
    "    return np.concatenate((frame,temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create x data and y data lists from audio files and jam files\n",
    "def songProcess(song_audio,notes,sr,hopSize = 1024,winSize = 4096,features = [],labels = []):\n",
    "\n",
    "  offsets = np.arange(0,len(song_audio),hopSize)\n",
    "  for (i,o) in enumerate(offsets):\n",
    "    original_frame_size = 0\n",
    "\n",
    "    frame = audio[o:o+winSize]\n",
    "\n",
    "    if original_frame_size == 0:\n",
    "      original_frame_size = frame.shape\n",
    "\n",
    "    note = 0\n",
    "    tiebreak = []\n",
    "\n",
    "    #Create labels from jams file data -- if multiple notes in frame, take longest duration\n",
    "    for j,(time,duration,value) in enumerate(notes):\n",
    "      note_start = time*sr\n",
    "      note_end = (time+duration)*sr\n",
    "      if o <= note_start < o+winSize:                 #note starts in frame\n",
    "        tiebreak.append(j)\n",
    "      elif o <= note_end < o+winSize:                  #note ends in frame\n",
    "        tiebreak.append(j)\n",
    "      elif note_start < o and o+winSize <= note_end: #note continuous thru frame\n",
    "        note = value\n",
    "\n",
    "    #if multiple notes in frame, choose one that played the longest in frame\n",
    "    if len(tiebreak) > 0:\n",
    "      if len(tiebreak) == 1:\n",
    "        note = notes[tiebreak[0]][2]\n",
    "      else:\n",
    "        max_dur = 0\n",
    "        max_note = 0\n",
    "        for index in tiebreak:\n",
    "          note_start = notes[index][0] * sr\n",
    "          note_duration = notes[index][1] * sr\n",
    "          frame_dur = 0\n",
    "          if note_start < o:\n",
    "            frame_dur = note_duration+note_start-o\n",
    "          elif note_start+note_duration > o+winSize:\n",
    "            frame_dur = o+winSize - note_start\n",
    "          else:\n",
    "            frame_dur = note_duration\n",
    "\n",
    "          if frame_dur > max_dur:\n",
    "            max_dur = frame_dur\n",
    "            max_note = notes[index][2]\n",
    "        note = max_note\n",
    "\n",
    "    #pad feature matrix\n",
    "    if len(frame) < winSize:\n",
    "      frame = pad(winSize, frame)\n",
    "\n",
    "    #append to feature and labels\n",
    "    features.append(frame)\n",
    "    labels.append(round(note))  #quantize to the nearest midi value\n",
    "\n",
    "  return features,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform T-SNE dimension reduction\n",
    "def tsneFit(X, comps):\n",
    "    tsne = TSNE(comps, learning_rate='auto', init='pca')\n",
    "    result = tsne.fit_transform(X)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to use input song and a trained model, to predict song's note/time information in MIDI\n",
    "def predict(song_audio, sr, model, hopSize, winSize, reduce=False):\n",
    "    \n",
    "    offsets = np.arange(0,len(song_audio),hopSize)\n",
    "    x_data = []\n",
    "\n",
    "    for (i,o) in enumerate(offsets):\n",
    "        frame = song_audio[o:o+winSize]\n",
    "        #pad\n",
    "        if len(frame) < winSize:\n",
    "            frame = pad(winSize, frame)\n",
    "        #append to features\n",
    "        x_data.append(frame)\n",
    "\n",
    "    #preprocess data\n",
    "    x_data = x_data_process(x_data,scale='global')\n",
    "\n",
    "    #dimension reduce\n",
    "    if reduce:\n",
    "        x_data = tsneFit(x_data, 2)\n",
    "\n",
    "    #predict. column 0 is note, column 1 is time\n",
    "    raw_results = model.predict(x_data)\n",
    "    midi_info = np.zeros((len(offsets),3))\n",
    "\n",
    "    for i,frame_note in enumerate(raw_results):\n",
    "        midi_info[i][0] = frame_note\n",
    "        midi_info[i][1] = hopSize*i/sr\n",
    "    midi_info[:,2] = np.absolute(np.array(x_data)).mean(axis=1) #amplitude of each frame\n",
    "\n",
    "    return midi_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sheet Music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "def closest_note(q_length,note_dur):\n",
    "    ratios = (4,2,1.5,1,0.5,0.25,0.125) #ratios used by music21 streams for each note\n",
    "    note_lengths = np.array([q_length*4, #whole note\n",
    "                             q_length*2, #half note\n",
    "                             q_length*1.5, #dotted quarter note\n",
    "                             q_length*1, #quarter note\n",
    "                             q_length*0.5, # eigth note\n",
    "                             q_length*0.25, # sixteenth note\n",
    "                             q_length*0.125]) # 32nd note note\n",
    "    best_note = np.argmin(np.absolute(note_lengths - note_dur))\n",
    "    return ratios[best_note]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "# Function to create sheet music from the note/time information output from predict()\n",
    "#           uses music21 streams\n",
    "#           uses frame amplitude to detect if the same note is played back to back\n",
    "# TODO: Save stream to midi file\n",
    "def to_midi_sheet(midi_info,outfile,bpm=120):\n",
    "    amp_error = 0.2 # amount of wiggle room between this frames amp and the prev's\n",
    "    q_length = 60/bpm #length of quarter note in seconds\n",
    "    min_note = q_length/2/2/2 # length of 32nd note\n",
    "\n",
    "    # hard code treble clef\n",
    "    s = music21.stream.Stream([music21.clef.TrebleClef()])\n",
    "\n",
    "    for i in range(1,len(midi_info)):\n",
    "        curr_frame_note = int(midi_info[i][0])\n",
    "        prev_frame_note = int(midi_info[i-1][0])\n",
    "        curr_frame_amp = midi_info[i][2]\n",
    "        prev_frame_amp = midi_info[i-1][2]\n",
    "        curr_note_start = 0\n",
    "\n",
    "        if curr_frame_note != prev_frame_note or curr_frame_amp > (1+amp_error)*prev_frame_amp:\n",
    "            # note length in seconds\n",
    "            note_dur = midi_info[i][1] - curr_note_start\n",
    "\n",
    "            if note_dur >= min_note:\n",
    "                length = closest_note(q_length,note_dur)\n",
    "                if prev_frame_note == 0:\n",
    "                    s.append(music21.note.Rest(quarterLength=length))\n",
    "                else:\n",
    "                    s.append(music21.note.Note(prev_frame_note,quarterLength=length))\n",
    "\n",
    "            # start tracking next note\n",
    "            curr_note_start = midi_info[i][1]\n",
    "\n",
    "    #show sheet music\n",
    "    s.show('musicxml.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Driver to load data and # of songs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# LOAD SONG AND JAM FILES\n",
    "song_path = r'DataSets/audio_mono-mic'\n",
    "jam_path = r'DataSets/annotation'\n",
    "MODE = 'solo'\n",
    "inputFiles = list(zip([x for x in os.listdir(song_path) if MODE in x],[x for x in os.listdir(jam_path) if MODE in x]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "##Set up features and labels for ML\n",
    "numSongs = 5\n",
    "counter = numSongs\n",
    "\n",
    "hopSize = 1024\n",
    "winSize = 1024\n",
    "\n",
    "XData,YData = [],[]\n",
    "for song_file,jam_file in inputFiles:\n",
    "    song = os.path.join(song_path,song_file)\n",
    "    jam = os.path.join(jam_path,jam_file)\n",
    "\n",
    "    audio,sr = load_audio_file(song)\n",
    "    note_info = loadNoteData(jam)\n",
    "\n",
    "    # Can pass in a feature matrix and label array if we want to concat multiple songs together\n",
    "    XData,YData = songProcess(audio,note_info,sr, hopSize, winSize)\n",
    "\n",
    "    counter -= 1\n",
    "    if counter == 0:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Neural Network Model Testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def neural_network(XTrain, XTest, YTrain, YTest, hidden_size, max_iter, solver, activation):\n",
    "    #Currently, using successful values from A1, further adjustment with the processed dataset will be needed\n",
    "    MLPC = MLPClassifier(hidden_layer_sizes=hidden_size, max_iter=max_iter, alpha=0.0001,\n",
    "                         learning_rate_init=0.001, solver=solver, activation=activation)\n",
    "    MLPC.fit(XTrain, YTrain)\n",
    "\n",
    "    return accuracy_score(YTest, MLPC.predict(XTest)), MLPC"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Model Test Accuracy: 0.5311355311355311\n"
     ]
    }
   ],
   "source": [
    "# NN Using No Scaling\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XData,YData,test_size=0.2)\n",
    "hidden_size=(60,120)\n",
    "max_iter=100000\n",
    "solver='adam'\n",
    "activation='tanh'\n",
    "accuracy, trained_model = neural_network(XTrain,XTest,YTrain,YTest,hidden_size, max_iter, solver, activation)\n",
    "print(\"NN Model Test Accuracy:\",accuracy)\n",
    "\n",
    "# Song to predict\n",
    "song = 'DataSets/audio_mono-mic/00_BN3-119-G_solo_mic.wav'\n",
    "\n",
    "# Get bpm\n",
    "predict_song_audio,predict_song_sr = load_audio_file(song)\n",
    "bpm = librosa.beat.beat_track(y=predict_song_audio.astype(float), sr=predict_song_sr)[0]\n",
    "\n",
    "# Predict\n",
    "midi_info = predict(predict_song_audio,predict_song_sr, trained_model,hopSize,winSize)\n",
    "\n",
    "# Convert to sheet music\n",
    "to_midi_sheet(midi_info,outfile=\"unscaled_nn_sheet_music\",bpm=round(bpm))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# NN Using local Scaling\n",
    "\n",
    "XData_local = x_data_process(XData, scale='local')\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XData_local,YData,test_size=0.2)\n",
    "hidden_size=(60,120)\n",
    "max_iter=100000\n",
    "solver='adam'\n",
    "activation='tanh'\n",
    "accuracy, trained_model = neural_network(XTrain,XTest,YTrain,YTest,hidden_size, max_iter, solver, activation)\n",
    "print(\"NN Model Test Accuracy:\",accuracy)\n",
    "\n",
    "# Song to predict\n",
    "song = 'DataSets/audio_mono-mic/00_BN3-119-G_solo_mic.wav'\n",
    "\n",
    "# Get bpm\n",
    "predict_song_audio,predict_song_sr = load_audio_file(song)\n",
    "bpm = librosa.beat.beat_track(y=predict_song_audio.astype(float), sr=predict_song_sr)[0]\n",
    "\n",
    "midi_info = predict(predict_song_audio,predict_song_sr,trained_model,hopSize,winSize)\n",
    "to_midi_sheet(midi_info,outfile=\"local_nn_sheet_music\",bpm=round(bpm))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN Using global Scaling\n",
    "XData_global = x_data_process(XData,scale='global')\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XData_global,YData,test_size=0.2)\n",
    "hidden_size=(60,120)\n",
    "max_iter=10000\n",
    "solver='adam'\n",
    "activation='tanh'\n",
    "accuracy, trained_model = neural_network(XTrain,XTest,YTrain,YTest,hidden_size, max_iter, solver, activation)\n",
    "print(\"NN Model Test Accuracy:\",accuracy)\n",
    "\n",
    "# song to predict\n",
    "song = 'DataSets/audio_mono-mic/00_BN3-119-G_solo_mic.wav'\n",
    "\n",
    "# Get bpm\n",
    "predict_song_audio,predict_song_sr = load_audio_file(song)\n",
    "bpm = librosa.beat.beat_track(y=predict_song_audio.astype(float), sr=predict_song_sr)[0]\n",
    "\n",
    "midi_info = predict(predict_song_audio,predict_song_sr,trained_model,hopSize,winSize)\n",
    "to_midi_sheet(midi_info,outfile=\"global_nn_sheet_music\",bpm=round(bpm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DrPag\\miniconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:982: FutureWarning: The PCA initialization in TSNE will change to have the standard deviation of PC1 equal to 1e-4 in 1.2. This will ensure better convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Model Test Accuracy: 0.6016483516483516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DrPag\\miniconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:982: FutureWarning: The PCA initialization in TSNE will change to have the standard deviation of PC1 equal to 1e-4 in 1.2. This will ensure better convergence.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# NN Using TSNE Reduction with local scaling\n",
    "XData_local = x_data_process(XData,scale='local')\n",
    "XDataTSNE = tsneFit(XData_local, 2)\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XDataTSNE,YData,test_size=0.2)\n",
    "hidden_size=(60,120)\n",
    "max_iter=10000\n",
    "solver='adam'\n",
    "activation='tanh'\n",
    "accuracy, trained_model = neural_network(XTrain,XTest,YTrain,YTest,hidden_size, max_iter, solver, activation)\n",
    "print(\"NN Model Test Accuracy:\",accuracy)\n",
    "\n",
    "# song to predict\n",
    "song = 'DataSets/audio_mono-mic/00_BN3-119-G_solo_mic.wav'\n",
    "\n",
    "#Get bpm\n",
    "predict_song_audio,predict_song_sr = load_audio_file(song)\n",
    "bpm = librosa.beat.beat_track(y=predict_song_audio.astype(float), sr=predict_song_sr)[0]\n",
    "\n",
    "midi_info = predict(predict_song_audio,predict_song_sr,trained_model,hopSize,winSize,reduce=True)\n",
    "to_midi_sheet(midi_info,outfile=\"tsne_local_nn_sheet_music\",bpm=round(bpm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussianSVM(XTrain, XTest, YTrain, YTest):\n",
    "    #Currently, using successful values from A2, further adjustment with the processed dataset will be needed\n",
    "    clf = SVC(kernel = 'rbf', gamma = 0.01, C = 150, max_iter=100000)\n",
    "    clf.fit(XTrain, YTrain)\n",
    "\n",
    "    return accuracy_score(YTest, clf.predict(XTest)), clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polySVM(XTrain, XTest, YTrain, YTest):\n",
    "    #Currently, using successful values from A2, further adjustment with the processed dataset will be needed\n",
    "    clf = SVC(kernel = 'poly', gamma = 0.01, C = 150, max_iter=100000)\n",
    "    clf.fit(XTrain, YTrain)\n",
    "\n",
    "    return accuracy_score(YTest, clf.predict(XTest)), clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigSVM(XTrain, XTest, YTrain, YTest):\n",
    "    #Currently, using successful values from A2, further adjustment with the processed dataset will be needed\n",
    "    clf = SVC(kernel = 'sigmoid', gamma = 0.01, C = 150, max_iter=100000)\n",
    "    clf.fit(XTrain, YTrain)\n",
    "\n",
    "    return accuracy_score(YTest, clf.predict(XTest)), clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preSVM(XTrain, XTest, YTrain, YTest):\n",
    "    #Currently, using successful values from A2, further adjustment with the processed dataset will be needed\n",
    "    clf = SVC(kernel = 'precomputed', C = 150, max_iter=100000)\n",
    "    clf.fit(XTrain, YTrain)\n",
    "\n",
    "    return accuracy_score(YTest, clf.predict(XTest)), clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBF Kernel - Gaussian SVM Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBF Kernel - No Scaling\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XData,YData,test_size=0.2)\n",
    "accuracy, trained_model = gaussianSVM(XTrain,XTest,YTrain,YTest)\n",
    "print(\"Gaussian SVM Model Test Accuracy:\",accuracy)\n",
    "\n",
    "# song to predict\n",
    "song = 'DataSets/audio_mono-mic/00_BN3-119-G_solo_mic.wav'\n",
    "\n",
    "#Get bpm\n",
    "predict_song_audio,predict_song_sr = load_audio_file(song)\n",
    "bpm = librosa.beat.beat_track(y=predict_song_audio.astype(float), sr=predict_song_sr)[0]\n",
    "\n",
    "midi_info = predict(predict_song_audio,predict_song_sr,trained_model,hopSize,winSize)\n",
    "to_midi_sheet(midi_info,outfile=\"unscaled_rbf_sheet_music\",bpm=round(bpm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBF Kernel - Local Scaling\n",
    "XDATA_local = x_data_process(XData,scale='local')\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XData_local,YData,test_size=0.2)\n",
    "accuracy, trained_model = gaussianSVM(XTrain,XTest,YTrain,YTest)\n",
    "print(\"Gaussian SVM Model Test Accuracy:\",accuracy)\n",
    "\n",
    "# song to predict\n",
    "song = 'DataSets/audio_mono-mic/00_BN3-119-G_solo_mic.wav'\n",
    "\n",
    "#Get bpm\n",
    "predict_song_audio,predict_song_sr = load_audio_file(song)\n",
    "bpm = librosa.beat.beat_track(y=predict_song_audio.astype(float), sr=predict_song_sr)[0]\n",
    "\n",
    "midi_info = predict(predict_song_audio,predict_song_sr,trained_model,hopSize,winSize)\n",
    "to_midi_sheet(midi_info,outfile=\"local_rbf_sheet_music\", bpm=round(bpm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBF Kernel - Global Scaling\n",
    "XData_global = x_data_process(XData,scale='global')\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XData_global,YData,test_size=0.2)\n",
    "accuracy, trained_model = gaussianSVM(XTrain,XTest,YTrain,YTest)\n",
    "print(\"Gaussian SVM Model Test Accuracy:\",accuracy)\n",
    "\n",
    "#song to predict\n",
    "song = 'DataSets/audio_mono-mic/00_BN3-119-G_solo_mic.wav'\n",
    "\n",
    "#Get bpm\n",
    "predict_song_audio,predict_song_sr = load_audio_file(song)\n",
    "bpm = librosa.beat.beat_track(y=predict_song_audio.astype(float), sr=predict_song_sr)[0]\n",
    "\n",
    "midi_info = predict(predict_song_audio,predict_song_sr,trained_model,hopSize,winSize)\n",
    "to_midi_sheet(midi_info,outfile=\"global_rbf_sheet_music\",bpm=round(bpm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBF Kernel - TSNE Scaling with local scaling\n",
    "XData_local = x_data_process(XData,scale='local')\n",
    "XDataTSNE = tsneFit(XData_local, 2)\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XDataTSNE,YData,test_size=0.2)\n",
    "accuracy, trained_model = gaussianSVM(XTrain,XTest,YTrain,YTest)\n",
    "print(\"Gaussian SVM Model Test Accuracy:\",accuracy)\n",
    "\n",
    "# song to predict\n",
    "song = 'DataSets/audio_mono-mic/00_BN3-119-G_solo_mic.wav'\n",
    "\n",
    "#Get bpm\n",
    "predict_song_audio,predict_song_sr = librosa.load(song)\n",
    "bpm = librosa.beat.beat_track(y=predict_song_audio.astype(float), sr=predict_song_sr)[0]\n",
    "\n",
    "midi_info = predict(predict_song_audio,predict_song_sr,trained_model,hopSize,winSize)\n",
    "to_midi_sheet(midi_info,outfile=\"tsne_local_rbf_sheet_music\",bpm=round(bpm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poly Kernel - Polynomial SVM Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Poly Kernel - No Scaling\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XData,YData,test_size=0.2)\n",
    "PSVM_1_accuracy, PSVM_1 = polySVM(XTrain,XTest,YTrain,YTest)\n",
    "print(\"Poly SVM Model Test Accuracy:\",PSVM_1_accuracy)\n",
    "\n",
    "# Song to predict\n",
    "song = 'DataSets/audio_mono-mic/00_BN3-119-G_solo_mic.wav'\n",
    "\n",
    "# Get bpm\n",
    "predict_song_audio,predict_song_sr = load_audio_file(song)\n",
    "bpm = librosa.beat.beat_track(y=predict_song_audio.astype(float), sr=predict_song_sr)[0]\n",
    "\n",
    "# Predict\n",
    "midi_info = predict(predict_song_audio,predict_song_sr, trained_model,hopSize,winSize)\n",
    "\n",
    "# Convert to sheet music\n",
    "to_midi_sheet(midi_info,outfile=\"unscaled_poly_sheet_music\",bpm=round(bpm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Poly Kernel - Local Scaling\n",
    "XData_local = x_data_process(XData,scale='local')\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XData_local,YData,test_size=0.2)\n",
    "PSVM_2_accuracy, PSVM_2 = polySVM(XTrain,XTest,YTrain,YTest)\n",
    "print(\"Poly SVM Model Test Accuracy:\",PSVM_2_accuracy)\n",
    "\n",
    "# Song to predict\n",
    "song = 'DataSets/audio_mono-mic/00_BN3-119-G_solo_mic.wav'\n",
    "\n",
    "# Get bpm\n",
    "predict_song_audio,predict_song_sr = load_audio_file(song)\n",
    "bpm = librosa.beat.beat_track(y=predict_song_audio.astype(float), sr=predict_song_sr)[0]\n",
    "\n",
    "# Predict\n",
    "midi_info = predict(predict_song_audio,predict_song_sr, trained_model,hopSize,winSize)\n",
    "\n",
    "# Convert to sheet music\n",
    "to_midi_sheet(midi_info,outfile=\"local_poly_sheet_music\",bpm=round(bpm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Poly Kernel - Global Scaling\n",
    "XData_global = x_data_process(XData,scale='global')\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XData_global,YData,test_size=0.2)\n",
    "PSVM_3_accuracy, PSVM_3 = polySVM(XTrain,XTest,YTrain,YTest)\n",
    "print(\"Poly SVM Model Test Accuracy:\",PSVM_3_accuracy)\n",
    "\n",
    "# Song to predict\n",
    "song = 'DataSets/audio_mono-mic/00_BN3-119-G_solo_mic.wav'\n",
    "\n",
    "# Get bpm\n",
    "predict_song_audio,predict_song_sr = load_audio_file(song)\n",
    "bpm = librosa.beat.beat_track(y=predict_song_audio.astype(float), sr=predict_song_sr)[0]\n",
    "\n",
    "# Predict\n",
    "midi_info = predict(predict_song_audio,predict_song_sr, trained_model,hopSize,winSize)\n",
    "\n",
    "# Convert to sheet music\n",
    "to_midi_sheet(midi_info,outfile=\"global_poly_sheet_music\",bpm=round(bpm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Poly Kernel - TSNE Scaling with local scaling\n",
    "XData_local = x_data_process(XData, scale='local')\n",
    "XDataTSNE = tsneFit(XData_local, 2)\n",
    "\n",
    "XTrain,XTest,YTrain,YTest = train_test_split(XDataTSNE,YData,test_size=0.2)\n",
    "PSVM_4_accuracy, PSVM_4 = polySVM(XTrain,XTest,YTrain,YTest)\n",
    "print(\"Poly SVM Model Test Accuracy:\",PSVM_4_accuracy)\n",
    "\n",
    "# Song to predict\n",
    "song = 'DataSets/audio_mono-mic/00_BN3-119-G_solo_mic.wav'\n",
    "\n",
    "# Get bpm\n",
    "predict_song_audio,predict_song_sr = load_audio_file(song)\n",
    "bpm = librosa.beat.beat_track(y=predict_song_audio.astype(float), sr=predict_song_sr)[0]\n",
    "\n",
    "# Predict\n",
    "midi_info = predict(predict_song_audio,predict_song_sr, trained_model,hopSize,winSize)\n",
    "\n",
    "# Convert to sheet music\n",
    "to_midi_sheet(midi_info,outfile=\"tsne_local_poly_sheet_music\",bpm=round(bpm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid Kernel - Sigmoid SVM Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Seng474Project.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}